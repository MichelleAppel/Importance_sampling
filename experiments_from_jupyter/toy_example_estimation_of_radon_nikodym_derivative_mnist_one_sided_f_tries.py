# -*- coding: utf-8 -*-
"""Toy_example_estimation_of_Radon-Nikodym_derivative_MNIST_one_sided_f_tries.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fhMo8F5OTbYGMOqwnKFavwwVsr_5Cqs1

# Toy example estimation of Radon-Nikodym derivative for MNIST dataset (one sided)

Equation (5) of the paper by Binkowski et al. explains that the Radon-Nikodym derivative $\frac{d \mathbb{Q}_y}{ \mathbb{P}_y^G}$ of the two domains exist under the assumptions they state. This derivative can also be seen as the ratio between the two distributions of the domains, and can be used to express the compensation for imbalance in the domains:

$\mathbb{E}_{Y \sim \mathbb{Q}_y}[D(Y)] = \mathbb{E}_{X \sim \mathbb{P}_x}[D(G(X)) \frac{d \mathbb{Q}_y}{ d\mathbb{P}_y^G}(G(X))]$

This expresses compensation for imbalance between the discriminator outputs, caused by the imbalance in the domain distributions. However, it does not necessarily have to be used for the imbalance in the discriminator outputs. It can be applied to any imbalance caused by the different domain distributions.

--

In other words, we are trying to study the situation where we don't deal with a discriminator but with any function, let it be $f$. This $f$ can be any function, e.g. identity, mean.... We try to compensate for imbalances in the two domains over which we compute the function:

$\mathbb{E}_{Y \sim \mathbb{Q}_y}[f(Y)] = \mathbb{E}_{X \sim \mathbb{P}_x}[f(G(X)) \frac{d \mathbb{Q}_y}{ d\mathbb{P}_y^G}(G(X))]$

Possible functions $f$ for MNIST:
* use the label
* pre-trained classifier

In this toy example we use try different possibilities for $f$:

0.   $f$ = real value for the label of the image (Like in Toy_example_estimation_of_Radon-Nikodym_derivative_MNIST_one_sided.ipynb : https://colab.research.google.com/drive/1REZfm-gHmH0_ozOROrofkCpM5eh0u2pI#scrollTo=FRC7j9BYJaM1)
1.   $f$ = mean of the pixel value over the whole image
2.   $f$ = image itself, that is weighted by the image's weight (and, after the weighting, an operation like a sum is applid over the whole batch)
3.   $f$ = fixed (not trained) randomly initialized neural network
4.   $f$ = fixed (not trained) randomly initialized neural network, with possibility to use hidden variables as $f$. $f$ can also be a tensor instead of a single value  



--

This toy example uses a simplified version of MNIST.

The dataset only has zeroes and ones, and the percentage of zeros/ones is specified by the user

--

The following toy example shows how we can use the Radon-Nikodym derivative for compensating the imbalance for the mean of the domains using $\bar{Y} = \bar{X}\frac{d \mathbb{Q}_y}{d \mathbb{P}_x}$.


Let $X = [1, 1, 1, 1, 1, 1, 1, 0, 0]$, with mean $\bar{X} = 0.8$ and <br />
Let $Y = [1, 1, 0, 0, 0, 0, 0, 0, 0]$, with mean $\bar{Y} = 0.2$

Then $[1, 1, 0, 0, 0, 0, 0, 0, 0] = [1, 1, 1, 1, 1, 1, 1, 0, 0] \cdot \frac{d \mathbb{Q}_y}{d \mathbb{P}_x}(X)$, and <br />
$\frac{d \mathbb{Q}_y}{d \mathbb{P}_x}(X) = [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 4, 4]$

This can be interpreted as the ratio between means of the domains for each of the samples. In this example the ratio can be calculated. However, in more complex situations, for example with images, the Radon-Nykodym derivative $\frac{d \mathbb{Q}_y}{d \mathbb{P}_x}$ is unknown and we may try to estimate it using a neural network $W$. This leads to the objective function

$\inf_{W \in \mathcal{W}} (\mathbb{E}_{X \sim \mathbb{P}_x} [D(G(X)) \cdot W(X)] - \mathbb{E}_{Y \sim \mathbb{Q}_y}[D(Y)])^2$

used by Binkowski et al. for compensation of distributions in the domains, using the discriminator output. Similarly, we can use such a network in our toy example.

### Initializations
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision.utils import make_grid
import torchvision
import numpy as np

import itertools

import matplotlib.pyplot as plt

def visualize_img_batch(batch):
    '''Visualizes image batch
    
    Parameters:
    batch (Tensor): An image batch
    '''
    grid = make_grid(batch.unsqueeze(1).unsqueeze(1).cpu(), nrow=8, padding=1, normalize=False, range=None, scale_each=False, pad_value=0.5)
    plt.imshow(grid.permute(1,2,0))
    plt.show()

'''def binary_data(size=(2**21, 1), ratio=0.5):
    
    idx = torch.randperm(size[0])[:int(ratio*size[0])] # Randomly choose indices according to the ratio

    print(idx)
    print(idx.shape)
    image_batch = torch.zeros(size)
    image_batch[idx] = 1
    
    return image_batch.clamp(0, 1).cuda().detach()'''

'''class ColorDataset(Dataset):
    ''The dataloader for the binary data
    '
    def __init__(self, ratio=0.5):

        self.ratio = ratio
        
        self.dataset = binary_data(ratio=self.ratio)
        
        self.example_imgs = self.example()
        
    def example(self):
        '
        Returns an example from each mode in the domain
        
        ''
        example_imgs = torch.zeros(size=(2, 1))
        example_imgs[1] = 1
        
        return example_imgs

    def __len__(self):
        return len(self.dataset)
    
    def __getitem__(self, idx):      
        return self.dataset[idx]'''

def visualize_MNIST_img_batch(batch):
    '''Visualizes image batch for MNIST
    
    Parameters:
    batch (Tensor): An image batch
    '''
    fig = plt.figure()
    for i in range(batch.shape[0]):
      plt.subplot(1,2,i+1)
      plt.tight_layout()
      plt.imshow(batch[i], cmap='gray', interpolation='none')
      plt.title("Ground Truth: {}".format(i))
      plt.xticks([])
      plt.yticks([])

def MNIST_binary_data(ratio=0.5):
    # ratio: percentage of zeroes
    #returns (data, labels) for MNIST with only zeroes and ones, with the given ratio

    MNIST = torchvision.datasets.MNIST('/files/', train=True, download=True,
                             transform=torchvision.transforms.Compose([
                               torchvision.transforms.ToTensor(),
                               torchvision.transforms.Normalize(
                                 (0.1307,), (0.3081,))
                             ]))
    
    idxm0 = MNIST.train_labels==0
    idxm1 = MNIST.train_labels==1 
    dim = len(idxm0)  

    n0 = torch.sum(idxm0)
    n1 = torch.sum(idxm1)
    tot = n0 + n1

    if ratio < n0.item()/tot.item():
      if ratio == 1:
        size = n0
      else:
        size = int(n1/(1-ratio))
      idx0 = np.where(idxm0)[0]
      idx0 = idx0[:int(size*ratio)]
      idx1 = np.where(idxm1)[0]
      #idx0 = [True if i in indices else False for i in range(len(idx0))]
    else:
      if ratio == 1:
        size = n1
      else:
        size = int(n0/ratio)
      idx0 = np.where(idxm0)[0]
      idx1 = np.where(idxm1)[0]
      idx1 = idx1[:int(size*(1-ratio))]
      #idx1 = [True if i in indices else False for i in range(len(idx1))]

    idx = idx0.tolist() + idx1.tolist()
    idxm = torch.tensor( [True if i in idx else False for i in range(dim)] )

    #labels = MNIST.train_labels[idxm]
    #data = MNIST.train_data[idxm]

    MNIST.targets = MNIST.train_labels[idx]
    MNIST.data = MNIST.train_data[idx]

    return MNIST 

'''# TEST
res = MNIST_binary_data(0.2)
#print(res)
#print(res.targets) #labels
#print(res.data) #data

ones = res.targets.sum().item()
tot = res.targets.shape[0]
print('zeroes =' + str(tot-ones))
print('ones =' + str(ones))
print('ratio =' + str((tot-ones)/tot))'''

class MNISTDataset(Dataset):
    '''The dataset for the MNIST binary data
    '''
    def __init__(self, ratio=0.5):

        self.ratio = ratio
        
        self.dataset = MNIST_binary_data(ratio=self.ratio)
        
        self.example_imgs = self.example()
        
    def example(self):
        '''
        Returns an example from each digit in the domain
        
        '''
        labels = self.dataset.targets
        data = self.dataset.data
        img0 = data[labels==0][0].unsqueeze(0)
        img1 = data[labels==1][0].unsqueeze(0)
        ex = torch.cat((img0, img1), 0)
              
        return ex

    def __len__(self):
        return len(self.dataset)
    
    def __getitem__(self, idx):      
        return self.dataset[idx]

'''# TEST
dataset = MNISTDataset()

fig = plt.figure()
for i in range(2):
  plt.subplot(1,2,i+1)
  plt.tight_layout()
  plt.imshow(dataset.example_imgs[i].cpu(), cmap='gray', interpolation='none')
  plt.title("Ground Truth: {}".format(i))
  plt.xticks([])
  plt.yticks([])'''

# Settings for domain A (red)
ratio_A = 0.2
dataset_A = MNISTDataset(ratio=ratio_A)
dataloader_A = DataLoader(dataset_A, batch_size=256, shuffle=True)

# Settings for domain B (green)
ratio_B = 0.5
dataset_B = MNISTDataset(ratio=ratio_B)
dataloader_B = DataLoader(dataset_B, batch_size=256, shuffle=True)

visualize_MNIST_img_batch(dataset_A.example_imgs.cpu())
visualize_MNIST_img_batch(dataset_B.example_imgs.cpu())

print(len(dataset_A))
print(len(dataset_B))

import cv2

def plot_hist(data):
    data = data.squeeze().cpu()
    plt.hist(data[data==1], weights=torch.ones(len(data[data==1]))/len(data), 
             color='black', bins=10, range= (0, 1))
    plt.hist(data[data==0], weights=torch.ones(len(data[data==0]))/len(data), 
             color='white', bins=10, range= (0, 1))
    plt.legend(['Imgs for label {}'.format(1), 
                'Imgs for label {}'.format(0)])
    plt.gca().set_facecolor('xkcd:gray')
    x_unique_count = torch.stack([(data==x_u).sum() for x_u in data.unique()])
    plt.show()

for i, (data_A, data_B) in enumerate(zip(dataloader_A, dataloader_B)):
    labs_A = data_A[1].double()
    labs_B = data_B[1].double()

    plot_hist(labs_A)
    plot_hist(labs_B)
    
    visualize_img_batch(torch.tensor(labs_A[:64]).unsqueeze(1).cuda())
    visualize_img_batch(torch.tensor(labs_B[:64]).unsqueeze(1).cuda())
    break

class WeightNet(nn.Module):
    '''A simple network that predicts the importances of the samples'''

    def __init__(self):
        super(WeightNet, self).__init__()
#        self.fc1 = nn.Linear(1, 1)
#        self.fc2 = nn.Linear(1, 1)
        self.softmax = nn.Softmax(dim=0)

        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.fc1 = nn.Linear(320, 40)
        self.fc2 = nn.Linear(40, 1)
        
    def forward(self, x):
        x = torch.sigmoid(F.max_pool2d(self.conv1(x), 2))
        x = torch.sigmoid(F.max_pool2d(self.conv2(x), 2))
        x = x.view(-1, 320)
        x = torch.sigmoid(self.fc1(x))
        x = self.fc2(x)
        return self.softmax(x), x

#        h1 = torch.sigmoid(self.fc1(x))
#        out = self.fc2(h1)
#        return self.softmax(out)
#         return out

"""####Compute the average & variance of assigned weights, for each number, in the batches"""

# compute the average weight/importance assigned to images in the batches, and the variance

import collections

def compute_average_prob(weight_network):
    weights_total = collections.defaultdict(torch.tensor)
    weights_mean = collections.defaultdict(float)
    weights_var = collections.defaultdict(float)
    mean_weight_batch = collections.defaultdict(float)
    ratio01s = []
    unnorm_weights_batch_list = collections.defaultdict(torch.tensor)
    
    for i, (batch_A, batch_B) in enumerate(zip(dataloader_A, dataloader_B)):

        real_A = batch_A[0].cuda()
        labels_A = batch_A[1].cuda()
        weights_batch, unnorm_weights_batch = weight_network(real_A)

        possible_labels, _ = torch.unique(labels_A).sort()
        for l in possible_labels:
            indices_with_label_l = labels_A == l.item()
            if l not in weights_total.keys():
              weights_total[l.item()] = weights_batch[indices_with_label_l]
            else:
              torch.cat((weights_total[l.item()], weights_batch[indices_with_label_l]), 0)
            
            mean_weight_batch[l.item()] = weights_batch[indices_with_label_l].mean().item() # mean weight assigned to '0' and '1' for each batch: p('0',batch_i) and p('1',batch_i)

            if l not in weights_total.keys():
              unnorm_weights_batch_list[l.item()] = torch.exp(unnorm_weights_batch[indices_with_label_l])
            else:
              torch.cat((unnorm_weights_batch_list[l.item()], torch.exp(unnorm_weights_batch[indices_with_label_l])), 0) #all w_i for all i that are '0', lets call this list_0; the same for '1', lets call it list_1

        ratio01s += [mean_weight_batch[0] / mean_weight_batch[1]] # ratio q(batch_i) = p('0',batch_i)/p('1',batch_i)
        
    for key in weights_total.keys():
        weights_mean[key] = weights_total[key].mean().item()
        weights_var[key] = weights_total[key].var().item()
    
    ratio01 = torch.tensor(ratio01s).mean().item() # average over all q(batch_i)

    unnorm_ratio01 = torch.tensor(unnorm_weights_batch_list[0]).mean().item() / torch.tensor(unnorm_weights_batch_list[1]).mean().item() # average over list_0, and independently over list_1, and take the quotient

    return weights_mean, weights_var, ratio01, unnorm_ratio01

#compute_average_prob(weight_network)

"""### Different functions for f"""

def f_0(labels_A, labels_B, w):
   '''f = label of the image '''

   L_A  = (labels_A.view(-1) * weight_normalization(w).view(-1)).sum()
   L_B = (labels_B.float()).mean()

   return L_A, L_B

def f_1(real_A, real_B, w):
   '''f = mean of each image '''

   L_A  = (torch.mean(real_A, dim=[2,3]).view(-1) * weight_normalization(w).view(-1)).sum()
   L_B = (torch.mean(real_B, dim=[2,3])).mean()

   return L_A, L_B

def f_2(real_A, real_B, w):
   '''f = image itself; each image is weighted, and the sum across all images is computed '''

   L_A  = (real_A * weight_normalization(w).repeat(28,28,1,1).permute(2,3,0,1)).sum()
   L_B = (real_B).mean()

   return L_A, L_B

class f_Net_2cl2fcl(nn.Module):
    ''' NN with 2 convolutional layers and fully connected layers'''

    def __init__(self):
        super(f_Net_2cl2fcl, self).__init__()
        self.softmax = nn.Softmax(dim=0)

        self.conv1 = nn.Conv2d(1, 4, kernel_size=5, stride = 2)
        self.conv2 = nn.Conv2d(4, 8, kernel_size=5, stride = 2)
        self.fc1 = nn.Linear(128, 36)
        self.fc2 = nn.Linear(36, 1)

        # randomly initialize the network
        nn.init.uniform_(self.conv1.weight)
        nn.init.uniform_(self.conv2.weight)
        nn.init.uniform_(self.fc1.weight)
        nn.init.uniform_(self.fc2.weight)

        # freezes the network (does not update the weights in Grad Desc.)
        for param in self.parameters():
           param.requires_grad = False
        
    def forward(self, x):
        cl1 = torch.sigmoid(self.conv1(x))
        cl2 = torch.sigmoid(self.conv2(cl1))
        cl2 = cl2.view(-1, 128)
        fc1 = torch.sigmoid(self.fc1(cl2))
        fc2 = self.fc2(fc1)
        fc2 = fc2.squeeze()

        # outputs a dictionary
        out = {}
        out['cl1'] = cl1.view(-1, 576) # hidden variables
        out['cl2'] = cl2 # hidden variables
        out['fc1'] = fc1 # hidden variables
        out['out'] = fc2 # output
        
        return out

class f_Net_1cl1fcl(nn.Module):
    ''' NN with 1 convolutional layer and 1 fully connected layer'''

    def __init__(self):
        super(f_Net_1cl1fcl, self).__init__()

        self.conv1 = nn.Conv2d(1, 4, kernel_size=5, stride = 4)
        self.fc2 = nn.Linear(144, 1)

        # randomly initialize the network
        nn.init.uniform_(self.conv1.weight)
        nn.init.uniform_(self.fc2.weight)

        # freezes the network (does not update the weights in Grad Desc.)
        for param in self.parameters():
           param.requires_grad = False
        
    def forward(self, x):
        cl1 = torch.sigmoid(self.conv1(x))
        cl1 = cl1.view(-1, 144)
        fc2 = torch.sigmoid(self.fc2(cl1))
        fc2 = fc2.squeeze()

        # outputs a dictionary
        out = {}
        out['cl1'] = cl1 # hidden variables
        out['out'] = fc2 # output
        
        return out

class f_Net_4fcl(nn.Module):
    ''' NN with 4 fully connected layers'''

    def __init__(self):
        super(f_Net_4fcl, self).__init__()

        self.fc1 = nn.Linear(784, 392)
        self.fc2 = nn.Linear(392, 128)
        self.fc3 = nn.Linear(128, 36)
        self.fc4 = nn.Linear(36, 1)

        # randomly initialize the network
        nn.init.uniform_(self.fc1.weight)
        nn.init.uniform_(self.fc2.weight)
        nn.init.uniform_(self.fc3.weight)
        nn.init.uniform_(self.fc4.weight)

        # freezes the network (does not update the weights in Grad Desc.)
        for param in self.parameters():
           param.requires_grad = False
        
    def forward(self, x):
        x = x.view(-1, 784)
        fc1 = torch.sigmoid(self.fc1(x))
        fc2 = torch.sigmoid(self.fc2(fc1))
        fc3 = torch.sigmoid(self.fc3(fc2))
        fc4 = torch.sigmoid(self.fc4(fc3))
        fc4 = fc4.squeeze()

        # outputs a dictionary
        out = {}
        out['fc1'] = fc1 # hidden variables
        out['fc2'] = fc2 # hidden variables
        out['fc3'] = fc3 # hidden variables
        out['out'] = fc4 # output
        
        return out

class f_Net_3fcl(nn.Module):
    ''' NN with 3 fully connected layers'''

    def __init__(self):
        super(f_Net_3fcl, self).__init__()

        self.fc1 = nn.Linear(784, 392)
        self.fc2 = nn.Linear(392, 36)
        self.fc4 = nn.Linear(36, 1)

        # randomly initialize the network
        nn.init.uniform_(self.fc1.weight)
        nn.init.uniform_(self.fc2.weight)
        nn.init.uniform_(self.fc4.weight)

        # freezes the network (does not update the weights in Grad Desc.)
        for param in self.parameters():
           param.requires_grad = False
        
    def forward(self, x):
        x = x.view(-1, 784)
        fc1 = torch.sigmoid(self.fc1(x))
        fc2 = torch.sigmoid(self.fc2(fc1))
        fc3 = torch.sigmoid(self.fc4(fc2))
        fc3 = fc3.squeeze()

        # outputs a dictionary
        out = {}
        out['fc1'] = fc1 # hidden variables
        out['fc2'] = fc2 # hidden variables
        out['out'] = fc3 # output

        return out

class f_Net_2fcl(nn.Module):
    ''' NN with 2 fully connected layers'''

    def __init__(self):
        super(f_Net_2fcl, self).__init__()

        self.fc1 = nn.Linear(784, 36)
        self.fc4 = nn.Linear(36, 1)

        # randomly initialize the network
        nn.init.uniform_(self.fc1.weight)
        nn.init.uniform_(self.fc4.weight)

        # freezes the network (does not update the weights in Grad Desc.)
        for param in self.parameters():
           param.requires_grad = False
        
    def forward(self, x):
        x = x.view(-1, 784)
        fc1 = torch.sigmoid(self.fc1(x))
        fc2 = torch.sigmoid(self.fc4(fc1))
        fc2 = fc2.squeeze()

        # outputs a dictionary
        out = {}
        out['fc1'] = fc1 # hidden variables
        out['out'] = fc2 # output
        
        return out

class f_Net_1fcl(nn.Module):
    ''' NN with 1 fully connected layer'''

    def __init__(self):
        super(f_Net_1fcl, self).__init__()

        self.fc1 = nn.Linear(784, 1)

        # randomly initialize the network
        nn.init.uniform_(self.fc1.weight)

        # freezes the network (does not update the weights in Grad Desc.)
        for param in self.parameters():
           param.requires_grad = False
        
    def forward(self, x):
        x = x.view(-1, 784)
        x = torch.sigmoid(self.fc1(x))
        x = x.squeeze()

        # outputs a dictionary
        out = {}
        out['out'] = x # output
        
        return out

def f_3(real_A, real_b, w):
   '''f = output of a fixed (not-trained and randomly initialized) NN for the image'''
   
   ''' Architectures that work: '''
   #f=f_Net_1fcl().cuda() # 1 fcl
   #f=f_Net_2fcl().cuda() # 2 fcl

   ''' Architectures that do not work: '''
   #f=f_Net_1cl1fcl().cuda() # 1 cl 1 fcl  
   f=f_Net_3fcl().cuda() # 3 fcl
   #f=f_Net_4fcl().cuda() # 4 fcl
   #f=f_Net_2cl2fcl().cuda() # 2 cl 2 fcl
   
   
   L_A  = (f(real_A)['out'].detach().view(-1) * weight_normalization(w).view(-1)).sum()
   L_B = (f(real_B)['out'].detach()).mean()

   return L_A, L_B

def f_4(real_A, real_b, w):
   '''f = hidden values of a fixed (not-trained and randomly initialized) NN for the image'''
   
   ''' Architectures that work: '''
   #f=f_Net_1fcl().cuda() # 1 fcl
   #f=f_Net_2fcl().cuda() # 2 fcl

   ''' Architectures that do not always work: '''
   f=f_Net_3fcl().cuda() # 3 fcl : works for f = fc1 or fc2, doesn't work for f = out
   #f=f_Net_4fcl().cuda() # 4 fcl : works for f = fc1 or fc2, doesn't work for f = fc3 or out
   #f=f_Net_1cl1fcl().cuda() # 1 cl 1 fcl : works for f = cl1, doesn't work for f = out   
   #f=f_Net_2cl2fcl().cuda() # 2 cl 2 fcl : works for f = cl1 or cl2, doesn't work for f = fc1 or out

   ''' Choose which part of the NN to use as f (output or any hidden variable) by selecting the correct entry in the dictionary output of the NN '''
   f_A = f(real_A)['fc1']
   if len(list(f_A.shape)) == 1:
     weights = weight_normalization(w).view(-1)
   else:
     dim = torch.cat([torch.tensor([1]), torch.tensor(f_A.shape[1:]).long()], dim = 0)
     weights = weight_normalization(w).repeat(tuple(dim))
   f_B = f(real_B)['fc1']
   
   L_A  = (f_A.detach() * weights).sum(dim = 0) # if f is a hidden variable, L_A and L_B are tensors, hence the sum(dim = 0)
   L_B = (f_B.detach()).mean(dim = 0)

   return L_A, L_B

"""### Training"""

class WeightNet(nn.Module):
    '''A simple network that predicts the importances of the samples'''

    def __init__(self):
        super(WeightNet, self).__init__()
#        self.fc1 = nn.Linear(1, 1)
#        self.fc2 = nn.Linear(1, 1)
        self.softmax = nn.Softmax(dim=0)

        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.fc1 = nn.Linear(320, 40)
        self.fc2 = nn.Linear(40, 1)
        
    def forward(self, x):
        x = torch.sigmoid(F.max_pool2d(self.conv1(x), 2))
        x = torch.sigmoid(F.max_pool2d(self.conv2(x), 2))
        x = x.view(-1, 320)
        x = torch.sigmoid(self.fc1(x))
        x = self.fc2(x)
        return self.softmax(x), x

#        h1 = torch.sigmoid(self.fc1(x))
#        out = self.fc2(h1)
#        return self.softmax(out)
#         return out

# Initialize the networks
weight_network = WeightNet().cuda()

# Initialize the optimizers
lr = 0.001
optimizer_w = optim.Adam(weight_network.parameters(), lr=lr)

losses_w = []

mean_A = []
mean_B = []

L_As = []
L_Bs = []

example_importances_A = []
example_importances_B = []

w_means = collections.defaultdict(list)
w_vars = collections.defaultdict(list)
ratio01s = []
unnorm_ratio01s = []

def weight_normalization(w):
    return w
#    return 0.5*(1 + w)

for epoch in range(4):
    for i, (batch_A, batch_B) in enumerate(zip(dataloader_A, dataloader_B)):

        real_A = batch_A[0].cuda()
        real_B = batch_B[0].cuda()
        labels_A = batch_A[1].cuda()
        labels_B = batch_B[1].cuda()

        # The weighting process
        w, unnorm_w = weight_network(real_A)
    
        # The loss function --------------------------------------------------------------------------------
        
        # Using f as objective function
        L_A, L_B = f_0(labels_A, labels_B, w)
        #L_A, L_B = f_1(real_A, real_B, w)
        #L_A, L_B = f_2(real_A, real_B, w)
        #L_A, L_B = f_3(real_A, real_B, w)
        # L_A, L_B = f_4(real_A, real_B, w)
        
        loss_w = ((L_A - L_B)**2).sum() # if f is a hidden variable, L_A and L_B are tensors, hence the sum() after the square
        
        mean_A += [real_A.mean()]
        mean_B += [real_B.mean()]

        # ---------------------------------------------------------------------------------------------------

        # Backward
        optimizer_w.zero_grad()
        loss_w.backward()
        optimizer_w.step()   

        # Store values --------------------------------------------------------------------------------------
        L_As += [L_A.sum().item()] # if f is a hidden variable, L_A and L_B are tensors, hence the sum()
        L_Bs += [L_B.sum().item()]
        
        losses_w += [loss_w.item()]
        
        w_a = weight_normalization((weight_network(dataset_A.example_imgs.float().unsqueeze(1).cuda())[0]))
        example_importances_A += [(w_a[0].item(), w_a[1].item())] # Store examples in a list
        

        if i % 5 == 0: # compute avg and var every 5 steps because it's quite slow
          mean, var, ratio01, unnorm_ratio01 = compute_average_prob(weight_network)
          for key in mean.keys():
            if (key not in w_means.keys()):
              w_means[key] = []
              w_vars[key] = [] 
            w_means[key] += [mean[key]]
            w_vars[key] += [var[key]]
          ratio01s += [ratio01]
          unnorm_ratio01s += [unnorm_ratio01]

        # ---------------------------------------------------------------------------------------------------

        # Print statistics
        if i % 500 == 0:
            print('step', i, 'loss_w: ', loss_w.item())
            
        if i % 5000 == 0 and i != 0:
            break

"""###Results

####Average & variance of assignedweights, for each number, in the batches
"""

# compute the average weight/importance assigned to images in the batches, and the variance

mean, var, ratio01, unnorm_ratio01 = compute_average_prob(weight_network)

# print stats
print("Means: ", mean)
print("Variance: ", var)
print("Ratio01: ", ratio01)
print("Not normalized ratio01: ", unnorm_ratio01)

# plot means and variances collected during the training
fig, axs = plt.subplots(2, 2, figsize=(10,10))
fig.suptitle('Weights means and variances collected during the training')

axs[0, 0].plot(w_means[0])
axs[0, 0].set_title('Mean weight for 0s')
axs[0, 1].plot(w_vars[0], 'tab:orange')
axs[0, 1].set_title('Variance of weights for 0s')
axs[1, 0].plot(w_means[1], 'tab:green')
axs[1, 0].set_title('Mean weight for 1s')
axs[1, 1].plot(w_vars[1], 'tab:red')
axs[1, 1].set_title('Variance of weights for 1s')

for ax in axs[:,0]:
    ax.set(xlabel='iterations / 5', ylabel='Mean')
for ax in axs[:,1]:
    ax.set(xlabel='iterations / 5', ylabel='Variance')




plt.figure(figsize=(10,6))
plt.title('Ratio between the weights assigned to 0 and 1: average in each batch, compute the ratio, then average through all the batches')
plt.xlabel('Training iterations')
plt.ylabel('Ratio 0/1')
# plt.yscale('symlog')
plt.plot(ratio01s)
plt.legend(['ratio01'])
plt.show()

plt.figure(figsize=(10,6))
plt.title('Ratio between the averages of not normalized weights for the classes')
plt.xlabel('Training iterations')
plt.ylabel('Unnormalized Ratio 0/1')
# plt.yscale('symlog')
plt.plot(unnorm_ratio01s)
plt.legend(['Unnorm_ratio01'])
plt.show()

"""####Loss"""

plt.figure(figsize=(10,6))
plt.title('Losses over iterations')
plt.xlabel('Training iterations')
plt.ylabel('Loss')
# plt.yscale('symlog')
plt.plot(losses_w)
plt.legend(['W'])
plt.show()

plt.figure(figsize=(10,6))
plt.title('Losses over iterations')
plt.xlabel('Training iterations')
plt.ylabel('Loss')
plt.plot(L_As)
plt.plot(L_Bs)
plt.legend(['L_A', 'L_B'])
plt.show()

"""####Assigned importances for the example images over the course of training"""

plt.figure(figsize=(10,6))
plt.title('Assigned importances for the toy example images over the course of training')
plt.plot(example_importances_A)
plt.legend(['Img A with value {} (p={})'.format(0, ratio_A), 
            'Img A with value {} (p={})'.format(1, 1-ratio_A)])
plt.ylabel('Assigned importance')
plt.xlabel('Training iterations')
plt.show()

example_importances_A[-1]

"""####Assigned importances for the linear combination of the example images"""

lambd = torch.linspace(0, 1, 64).repeat(28,28,1,1).permute(3,2,0,1)
lin_comb = lambd * dataset_A.example_imgs[0] + (1-lambd) * dataset_A.example_imgs[1]

weights, _ = weight_network(lin_comb.cuda())
weights = weights.cpu().detach().numpy()
plt.figure(figsize=(10,6))
plt.title('Assigned importances for linear combination between images of 0 and 1 [lambda * 0 + (1-lambda * 1)]')
plt.plot(torch.linspace(0, 1, 64), weights)
plt.ylabel('Assigned importance')
plt.xlabel('Lambda value')
plt.show()

"""Other"""

a = example_importances_A[-1][0]
b = example_importances_A[-1][1]
a, b

# We find that the ratio is equal
a/b, ratio_A**2/ratio_B**2

print(ratio_A/ratio_B)
print(ratio_B/ratio_A)

plt.figure(figsize=(10,6))
plt.title('Losses over iterations')
plt.xlabel('Training iterations')
plt.ylabel('Mean')
plt.plot(mean_A)
plt.plot(mean_B)
plt.legend(['mean_A', 'mean_B'])
plt.show()

