{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance sampling: toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: making a dataloader that generates black and white images only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image(color='black', size=(8, 8, 3)):\n",
    "    ''' Generates a black or white image as toy example'''\n",
    "    if color == 'black':\n",
    "        return torch.zeros(size)\n",
    "    else:\n",
    "        return torch.ones(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_img(img):\n",
    "    '''Visualize the images'''\n",
    "    plt.imshow(img.cpu())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the function\n",
    "# visualize_img(generate_image('black'))\n",
    "# visualize_img(generate_image('white'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_image_batch(size=(16, 8, 8, 3), ratio=0.5):\n",
    "    '''Makes a random image batch of size (batch_size, height, width, channels) \n",
    "    with black to white ratio of value ratio\n",
    "    '''\n",
    "    idx = torch.randperm(size[0])[:int(ratio*size[0])]\n",
    "    image_batch = torch.zeros(size)\n",
    "    image_batch[idx] = 1\n",
    "    return image_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataloader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_weight_network(img):\n",
    "    '''Returns weight based on image (toy example)'''\n",
    "    return img.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackWhiteDataset(Dataset):\n",
    "    '''The dataloader for the black and white images'''\n",
    "    def __init__(self, weight_network):\n",
    "        self.dataset = random_image_batch()\n",
    "        \n",
    "        self.weight_network = weight_network\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def accept_sample(self, weight_network, img):\n",
    "        # Returns True if the image is accepted, False if rejected\n",
    "        weight = weight_network(img)\n",
    "        return bool(list(torch.utils.data.sampler.WeightedRandomSampler([1-weight, weight], 1))[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Random permutation on the dataset order (is this equivalent to uniform sampling?)\n",
    "        all_idx = torch.randperm(len(dataset))\n",
    "        \n",
    "        # Loop through the samples and return once accepted\n",
    "        for i in all_idx:\n",
    "            accept = self.accept_sample(self.weight_network, self.dataset[i])\n",
    "            if accept:\n",
    "                return self.dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BlackWhiteDataset(dummy_weight_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This should only sample white images as they have a probablity of 1 to be sampled (black has 0)\n",
    "visualize_img(dataset[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
